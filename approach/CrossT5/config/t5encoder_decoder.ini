[Data]
data_dir = ../datasets/pure_t5
middle_res_dir = ../datasets/middle_res/sub_process_data
train_file = %(data_dir)s/train.pkl
dev_file = %(data_dir)s/dev.pkl
test_file = %(data_dir)s/test.pkl
pretrained_embeddings_file = %(data_dir)s/vocabs/pretrain.vec

[Save]
data_dir = ../datasets/pure_t5
save_dir = ../outmodels/pure_t5
config_file = %(save_dir)s/config.cfg
save_model_path = %(save_dir)s/model
save_vocab_path = %(save_dir)s/vocab
load_dir = ../outmodel/blstm/token
load_model_path = %(load_dir)s/model
load_vocab_path = %(load_dir)s/vocab
generation_dir = %(save_dir)s/generations

[Optimizer]
learning_rate = 1e-5
decay = .75
decay_steps = 1000
beta_1 = .9
beta_2 = .9
epsilon = 1e-8
clip = 1.0

[Network]
word_dims = 512
context_max_len = 1024
query_max_len = 64
char_seq_max_len = 15
encoder_layers = 8
decoder_layers = 8
char_vocab_size = 32100
num_heads = 8
input_dropout = 0.1
max_generated_len = 50

[Run]
train_iters = 800
train_batch_size = 12
val_batch_size = 20
test_batch_size = 40
validate_every = 500
update_every = 1
save_after = 1
save_every = 1000
accumulation_steps = 10
beam_size = 5

[Beam]
alpha = 0.7
beta = 0.6

